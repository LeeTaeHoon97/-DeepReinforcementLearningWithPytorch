{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep Reinforcement Learning using AlphaZero methodology\n",
    "\n",
    "Please see https://applied-data.science/blog/how-to-build-your-own-alphazero-ai-using-python-and-keras/ for further notes on the codebase"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. First load the core libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "# %matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import numpy as np\n",
    "np.set_printoptions(suppress=True)\n",
    "\n",
    "from shutil import copyfile\n",
    "import random\n",
    "from importlib import reload\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# from keras.utils import plot_model\n",
    "\n",
    "from game import Game, GameState\n",
    "from agent import Agent\n",
    "from memory import Memory\n",
    "from model import Residual_CNN\n",
    "from funcs import playMatches, playMatchesBetweenVersions\n",
    "\n",
    "import loggers as lg\n",
    "\n",
    "from settings import run_folder, run_archive_folder\n",
    "import initialise\n",
    "import pickle\n",
    "\n",
    "import copy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Now run this block to start the learning process\n",
    "\n",
    "This block loops for ever, continually learning from new game data.\n",
    "\n",
    "The current best model and memories are saved in the run folder so you can kill the process and restart from the last checkpoint."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "ITERATION NUMBER 1\n",
      "BEST PLAYER VERSION 0\n",
      "SELF PLAYING 30 EPISODES...\n",
      "1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 "
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\dlxog\\Documents\\GitHub\\-DeepReinforcementLearningWithPytorch\\run.ipynb Cell 5'\u001b[0m in \u001b[0;36m<cell line: 56>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/dlxog/Documents/GitHub/-DeepReinforcementLearningWithPytorch/run.ipynb#ch0000004?line=66'>67</a>\u001b[0m \u001b[39m######## SELF PLAY ########\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/dlxog/Documents/GitHub/-DeepReinforcementLearningWithPytorch/run.ipynb#ch0000004?line=67'>68</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m'\u001b[39m\u001b[39mSELF PLAYING \u001b[39m\u001b[39m'\u001b[39m \u001b[39m+\u001b[39m \u001b[39mstr\u001b[39m(config\u001b[39m.\u001b[39mEPISODES) \u001b[39m+\u001b[39m \u001b[39m'\u001b[39m\u001b[39m EPISODES...\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/dlxog/Documents/GitHub/-DeepReinforcementLearningWithPytorch/run.ipynb#ch0000004?line=68'>69</a>\u001b[0m _, memory, _, _ \u001b[39m=\u001b[39m playMatches(best_player, best_player,config\u001b[39m.\u001b[39;49mEPISODES , lg\u001b[39m.\u001b[39;49mlogger_main, turns_until_tau0 \u001b[39m=\u001b[39;49m config\u001b[39m.\u001b[39;49mTURNS_UNTIL_TAU0, memory \u001b[39m=\u001b[39;49m memory)  \u001b[39m#######config.EPISODES\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/dlxog/Documents/GitHub/-DeepReinforcementLearningWithPytorch/run.ipynb#ch0000004?line=69'>70</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m'\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m'\u001b[39m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/dlxog/Documents/GitHub/-DeepReinforcementLearningWithPytorch/run.ipynb#ch0000004?line=71'>72</a>\u001b[0m memory\u001b[39m.\u001b[39mclear_stmemory()\n",
      "File \u001b[1;32mc:\\Users\\dlxog\\Documents\\GitHub\\-DeepReinforcementLearningWithPytorch\\funcs.py:86\u001b[0m, in \u001b[0;36mplayMatches\u001b[1;34m(player1, player2, EPISODES, logger, turns_until_tau0, memory, goes_first)\u001b[0m\n\u001b[0;32m     <a href='file:///c%3A/Users/dlxog/Documents/GitHub/-DeepReinforcementLearningWithPytorch/funcs.py?line=83'>84</a>\u001b[0m \u001b[39m#### Run the MCTS algo and return an action\u001b[39;00m\n\u001b[0;32m     <a href='file:///c%3A/Users/dlxog/Documents/GitHub/-DeepReinforcementLearningWithPytorch/funcs.py?line=84'>85</a>\u001b[0m \u001b[39mif\u001b[39;00m turn \u001b[39m<\u001b[39m turns_until_tau0:\n\u001b[1;32m---> <a href='file:///c%3A/Users/dlxog/Documents/GitHub/-DeepReinforcementLearningWithPytorch/funcs.py?line=85'>86</a>\u001b[0m     action, pi, MCTS_value, NN_value \u001b[39m=\u001b[39m players[state\u001b[39m.\u001b[39;49mplayerTurn][\u001b[39m'\u001b[39;49m\u001b[39magent\u001b[39;49m\u001b[39m'\u001b[39;49m]\u001b[39m.\u001b[39;49mact(state, \u001b[39m1\u001b[39;49m)\n\u001b[0;32m     <a href='file:///c%3A/Users/dlxog/Documents/GitHub/-DeepReinforcementLearningWithPytorch/funcs.py?line=86'>87</a>\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m     <a href='file:///c%3A/Users/dlxog/Documents/GitHub/-DeepReinforcementLearningWithPytorch/funcs.py?line=87'>88</a>\u001b[0m     action, pi, MCTS_value, NN_value \u001b[39m=\u001b[39m players[state\u001b[39m.\u001b[39mplayerTurn][\u001b[39m'\u001b[39m\u001b[39magent\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m.\u001b[39mact(state, \u001b[39m0\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\dlxog\\Documents\\GitHub\\-DeepReinforcementLearningWithPytorch\\agent.py:110\u001b[0m, in \u001b[0;36mact\u001b[1;34m(self, state, tau)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Users/dlxog/Documents/GitHub/-DeepReinforcementLearningWithPytorch/agent.py?line=106'>107</a>\u001b[0m \tlg.logger_mcts.info('***************************')\n\u001b[0;32m    <a href='file:///c%3A/Users/dlxog/Documents/GitHub/-DeepReinforcementLearningWithPytorch/agent.py?line=107'>108</a>\u001b[0m \tself.simulate()\n\u001b[1;32m--> <a href='file:///c%3A/Users/dlxog/Documents/GitHub/-DeepReinforcementLearningWithPytorch/agent.py?line=109'>110</a>\u001b[0m #### get action values\n\u001b[0;32m    <a href='file:///c%3A/Users/dlxog/Documents/GitHub/-DeepReinforcementLearningWithPytorch/agent.py?line=110'>111</a>\u001b[0m pi, values = self.getAV(1)\n\u001b[0;32m    <a href='file:///c%3A/Users/dlxog/Documents/GitHub/-DeepReinforcementLearningWithPytorch/agent.py?line=112'>113</a>\u001b[0m ####pick the action\n",
      "File \u001b[1;32mc:\\Users\\dlxog\\Documents\\GitHub\\-DeepReinforcementLearningWithPytorch\\agent.py:85\u001b[0m, in \u001b[0;36msimulate\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     <a href='file:///c%3A/Users/dlxog/Documents/GitHub/-DeepReinforcementLearningWithPytorch/agent.py?line=81'>82</a>\u001b[0m self.mcts.root.state.render(lg.logger_mcts)\n\u001b[0;32m     <a href='file:///c%3A/Users/dlxog/Documents/GitHub/-DeepReinforcementLearningWithPytorch/agent.py?line=82'>83</a>\u001b[0m lg.logger_mcts.info('CURRENT PLAYER...%d', self.mcts.root.state.playerTurn)\n\u001b[1;32m---> <a href='file:///c%3A/Users/dlxog/Documents/GitHub/-DeepReinforcementLearningWithPytorch/agent.py?line=84'>85</a>\u001b[0m ##### MOVE THE LEAF NODE\n\u001b[0;32m     <a href='file:///c%3A/Users/dlxog/Documents/GitHub/-DeepReinforcementLearningWithPytorch/agent.py?line=85'>86</a>\u001b[0m leaf, value, done, breadcrumbs = self.mcts.moveToLeaf()\n\u001b[0;32m     <a href='file:///c%3A/Users/dlxog/Documents/GitHub/-DeepReinforcementLearningWithPytorch/agent.py?line=86'>87</a>\u001b[0m leaf.state.render(lg.logger_mcts)\n",
      "File \u001b[1;32mE:\\miniconda3\\envs\\torch_env\\lib\\logging\\__init__.py:1468\u001b[0m, in \u001b[0;36mLogger.info\u001b[1;34m(self, msg, *args, **kwargs)\u001b[0m\n\u001b[0;32m   <a href='file:///e%3A/miniconda3/envs/torch_env/lib/logging/__init__.py?line=1458'>1459</a>\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m   <a href='file:///e%3A/miniconda3/envs/torch_env/lib/logging/__init__.py?line=1459'>1460</a>\u001b[0m \u001b[39mLog 'msg % args' with severity 'INFO'.\u001b[39;00m\n\u001b[0;32m   <a href='file:///e%3A/miniconda3/envs/torch_env/lib/logging/__init__.py?line=1460'>1461</a>\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   <a href='file:///e%3A/miniconda3/envs/torch_env/lib/logging/__init__.py?line=1464'>1465</a>\u001b[0m \u001b[39mlogger.info(\"Houston, we have a %s\", \"interesting problem\", exc_info=1)\u001b[39;00m\n\u001b[0;32m   <a href='file:///e%3A/miniconda3/envs/torch_env/lib/logging/__init__.py?line=1465'>1466</a>\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m   <a href='file:///e%3A/miniconda3/envs/torch_env/lib/logging/__init__.py?line=1466'>1467</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39misEnabledFor(INFO):\n\u001b[1;32m-> <a href='file:///e%3A/miniconda3/envs/torch_env/lib/logging/__init__.py?line=1467'>1468</a>\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_log(INFO, msg, args, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mE:\\miniconda3\\envs\\torch_env\\lib\\logging\\__init__.py:1615\u001b[0m, in \u001b[0;36mLogger._log\u001b[1;34m(self, level, msg, args, exc_info, extra, stack_info, stacklevel)\u001b[0m\n\u001b[0;32m   <a href='file:///e%3A/miniconda3/envs/torch_env/lib/logging/__init__.py?line=1611'>1612</a>\u001b[0m         exc_info \u001b[39m=\u001b[39m sys\u001b[39m.\u001b[39mexc_info()\n\u001b[0;32m   <a href='file:///e%3A/miniconda3/envs/torch_env/lib/logging/__init__.py?line=1612'>1613</a>\u001b[0m record \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmakeRecord(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mname, level, fn, lno, msg, args,\n\u001b[0;32m   <a href='file:///e%3A/miniconda3/envs/torch_env/lib/logging/__init__.py?line=1613'>1614</a>\u001b[0m                          exc_info, func, extra, sinfo)\n\u001b[1;32m-> <a href='file:///e%3A/miniconda3/envs/torch_env/lib/logging/__init__.py?line=1614'>1615</a>\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mhandle(record)\n",
      "File \u001b[1;32mE:\\miniconda3\\envs\\torch_env\\lib\\logging\\__init__.py:1625\u001b[0m, in \u001b[0;36mLogger.handle\u001b[1;34m(self, record)\u001b[0m\n\u001b[0;32m   <a href='file:///e%3A/miniconda3/envs/torch_env/lib/logging/__init__.py?line=1617'>1618</a>\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m   <a href='file:///e%3A/miniconda3/envs/torch_env/lib/logging/__init__.py?line=1618'>1619</a>\u001b[0m \u001b[39mCall the handlers for the specified record.\u001b[39;00m\n\u001b[0;32m   <a href='file:///e%3A/miniconda3/envs/torch_env/lib/logging/__init__.py?line=1619'>1620</a>\u001b[0m \n\u001b[0;32m   <a href='file:///e%3A/miniconda3/envs/torch_env/lib/logging/__init__.py?line=1620'>1621</a>\u001b[0m \u001b[39mThis method is used for unpickled records received from a socket, as\u001b[39;00m\n\u001b[0;32m   <a href='file:///e%3A/miniconda3/envs/torch_env/lib/logging/__init__.py?line=1621'>1622</a>\u001b[0m \u001b[39mwell as those created locally. Logger-level filtering is applied.\u001b[39;00m\n\u001b[0;32m   <a href='file:///e%3A/miniconda3/envs/torch_env/lib/logging/__init__.py?line=1622'>1623</a>\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m   <a href='file:///e%3A/miniconda3/envs/torch_env/lib/logging/__init__.py?line=1623'>1624</a>\u001b[0m \u001b[39mif\u001b[39;00m (\u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdisabled) \u001b[39mand\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfilter(record):\n\u001b[1;32m-> <a href='file:///e%3A/miniconda3/envs/torch_env/lib/logging/__init__.py?line=1624'>1625</a>\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcallHandlers(record)\n",
      "File \u001b[1;32mE:\\miniconda3\\envs\\torch_env\\lib\\logging\\__init__.py:1687\u001b[0m, in \u001b[0;36mLogger.callHandlers\u001b[1;34m(self, record)\u001b[0m\n\u001b[0;32m   <a href='file:///e%3A/miniconda3/envs/torch_env/lib/logging/__init__.py?line=1684'>1685</a>\u001b[0m     found \u001b[39m=\u001b[39m found \u001b[39m+\u001b[39m \u001b[39m1\u001b[39m\n\u001b[0;32m   <a href='file:///e%3A/miniconda3/envs/torch_env/lib/logging/__init__.py?line=1685'>1686</a>\u001b[0m     \u001b[39mif\u001b[39;00m record\u001b[39m.\u001b[39mlevelno \u001b[39m>\u001b[39m\u001b[39m=\u001b[39m hdlr\u001b[39m.\u001b[39mlevel:\n\u001b[1;32m-> <a href='file:///e%3A/miniconda3/envs/torch_env/lib/logging/__init__.py?line=1686'>1687</a>\u001b[0m         hdlr\u001b[39m.\u001b[39;49mhandle(record)\n\u001b[0;32m   <a href='file:///e%3A/miniconda3/envs/torch_env/lib/logging/__init__.py?line=1687'>1688</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m c\u001b[39m.\u001b[39mpropagate:\n\u001b[0;32m   <a href='file:///e%3A/miniconda3/envs/torch_env/lib/logging/__init__.py?line=1688'>1689</a>\u001b[0m     c \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m    \u001b[39m#break out\u001b[39;00m\n",
      "File \u001b[1;32mE:\\miniconda3\\envs\\torch_env\\lib\\logging\\__init__.py:967\u001b[0m, in \u001b[0;36mHandler.handle\u001b[1;34m(self, record)\u001b[0m\n\u001b[0;32m    <a href='file:///e%3A/miniconda3/envs/torch_env/lib/logging/__init__.py?line=964'>965</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39macquire()\n\u001b[0;32m    <a href='file:///e%3A/miniconda3/envs/torch_env/lib/logging/__init__.py?line=965'>966</a>\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> <a href='file:///e%3A/miniconda3/envs/torch_env/lib/logging/__init__.py?line=966'>967</a>\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49memit(record)\n\u001b[0;32m    <a href='file:///e%3A/miniconda3/envs/torch_env/lib/logging/__init__.py?line=967'>968</a>\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[0;32m    <a href='file:///e%3A/miniconda3/envs/torch_env/lib/logging/__init__.py?line=968'>969</a>\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrelease()\n",
      "File \u001b[1;32mE:\\miniconda3\\envs\\torch_env\\lib\\logging\\__init__.py:1209\u001b[0m, in \u001b[0;36mFileHandler.emit\u001b[1;34m(self, record)\u001b[0m\n\u001b[0;32m   <a href='file:///e%3A/miniconda3/envs/torch_env/lib/logging/__init__.py?line=1206'>1207</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstream \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m   <a href='file:///e%3A/miniconda3/envs/torch_env/lib/logging/__init__.py?line=1207'>1208</a>\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstream \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_open()\n\u001b[1;32m-> <a href='file:///e%3A/miniconda3/envs/torch_env/lib/logging/__init__.py?line=1208'>1209</a>\u001b[0m StreamHandler\u001b[39m.\u001b[39;49memit(\u001b[39mself\u001b[39;49m, record)\n",
      "File \u001b[1;32mE:\\miniconda3\\envs\\torch_env\\lib\\logging\\__init__.py:1102\u001b[0m, in \u001b[0;36mStreamHandler.emit\u001b[1;34m(self, record)\u001b[0m\n\u001b[0;32m   <a href='file:///e%3A/miniconda3/envs/torch_env/lib/logging/__init__.py?line=1099'>1100</a>\u001b[0m     \u001b[39m# issue 35046: merged two stream.writes into one.\u001b[39;00m\n\u001b[0;32m   <a href='file:///e%3A/miniconda3/envs/torch_env/lib/logging/__init__.py?line=1100'>1101</a>\u001b[0m     stream\u001b[39m.\u001b[39mwrite(msg \u001b[39m+\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mterminator)\n\u001b[1;32m-> <a href='file:///e%3A/miniconda3/envs/torch_env/lib/logging/__init__.py?line=1101'>1102</a>\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mflush()\n\u001b[0;32m   <a href='file:///e%3A/miniconda3/envs/torch_env/lib/logging/__init__.py?line=1102'>1103</a>\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mRecursionError\u001b[39;00m:  \u001b[39m# See issue 36272\u001b[39;00m\n\u001b[0;32m   <a href='file:///e%3A/miniconda3/envs/torch_env/lib/logging/__init__.py?line=1103'>1104</a>\u001b[0m     \u001b[39mraise\u001b[39;00m\n",
      "File \u001b[1;32mE:\\miniconda3\\envs\\torch_env\\lib\\logging\\__init__.py:1082\u001b[0m, in \u001b[0;36mStreamHandler.flush\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   <a href='file:///e%3A/miniconda3/envs/torch_env/lib/logging/__init__.py?line=1079'>1080</a>\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m   <a href='file:///e%3A/miniconda3/envs/torch_env/lib/logging/__init__.py?line=1080'>1081</a>\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstream \u001b[39mand\u001b[39;00m \u001b[39mhasattr\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstream, \u001b[39m\"\u001b[39m\u001b[39mflush\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[1;32m-> <a href='file:///e%3A/miniconda3/envs/torch_env/lib/logging/__init__.py?line=1081'>1082</a>\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mstream\u001b[39m.\u001b[39;49mflush()\n\u001b[0;32m   <a href='file:///e%3A/miniconda3/envs/torch_env/lib/logging/__init__.py?line=1082'>1083</a>\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[0;32m   <a href='file:///e%3A/miniconda3/envs/torch_env/lib/logging/__init__.py?line=1083'>1084</a>\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrelease()\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "lg.logger_main.info('=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*')\n",
    "lg.logger_main.info('=*=*=*=*=*=.      NEW LOG      =*=*=*=*=*')\n",
    "lg.logger_main.info('=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*')\n",
    "\n",
    "env = Game()\n",
    "\n",
    "# If loading an existing neural network, copy the config file to root\n",
    "if initialise.INITIAL_RUN_NUMBER != None:\n",
    "    copyfile(run_archive_folder + env.name + '/run' + str(initialise.INITIAL_RUN_NUMBER).zfill(4) + '/config.py', './config.py')\n",
    "\n",
    "import config\n",
    "\n",
    "######## LOAD MEMORIES IF NECESSARY ########\n",
    "\n",
    "if initialise.INITIAL_MEMORY_VERSION == None:\n",
    "    memory = Memory(config.MEMORY_SIZE)\n",
    "else:\n",
    "    print('LOADING MEMORY VERSION ' + str(initialise.INITIAL_MEMORY_VERSION) + '...')\n",
    "    memory = pickle.load( open( run_archive_folder + env.name + '/run' + str(initialise.INITIAL_RUN_NUMBER).zfill(4) + \"/memory/memory\" + str(initialise.INITIAL_MEMORY_VERSION).zfill(4) + \".p\",   \"rb\" ) )\n",
    "\n",
    "######## LOAD MODEL IF NECESSARY ########\n",
    "\n",
    "# create an untrained neural network objects from the config file\n",
    "current_NN = Residual_CNN(config.REG_CONST, (2,) + env.grid_shape,   env.action_size, config.HIDDEN_CNN_LAYERS)\n",
    "best_NN = Residual_CNN(config.REG_CONST,  (2,) +  env.grid_shape,   env.action_size, config.HIDDEN_CNN_LAYERS)\n",
    "\n",
    "#If loading an existing neural netwrok, set the weights from that model\n",
    "if initialise.INITIAL_MODEL_VERSION != None:\n",
    "    best_player_version  = initialise.INITIAL_MODEL_VERSION\n",
    "    print('LOADING MODEL VERSION ' + str(initialise.INITIAL_MODEL_VERSION) + '...')\n",
    "    #read/write, s model save, load로 통합\n",
    "    #set/get_weights 를 load state_dict으로 변경\n",
    "    m_tmp = best_NN.read(env.name, initialise.INITIAL_RUN_NUMBER, best_player_version)\n",
    "    current_NN.load_state_dict(m_tmp)\n",
    "    best_NN.load_state_dict(m_tmp)\n",
    "#otherwise just ensure the weights on the two players are the same\n",
    "else:\n",
    "    best_player_version = 0\n",
    "    best_NN=copy.deepcopy(current_NN)\n",
    "    #pytorch 에서는 set/get_weights가 존재하지않음, 따라서 현재의 state_dict을 load\n",
    "    # best_NN.model.set_weights(current_NN.model.get_weights())\n",
    "\n",
    "#copy the config file to the run folder\n",
    "copyfile('./config.py', run_folder + 'config.py')\n",
    "# plot_model(current_NN.model, to_file=run_folder + 'models/model.png', show_shapes = True)\n",
    "\n",
    "print('\\n')\n",
    "\n",
    "######## CREATE THE PLAYERS ########\n",
    "\n",
    "current_player = Agent('current_player', env.state_size, env.action_size, config.MCTS_SIMS, config.CPUCT, current_NN)\n",
    "best_player = Agent('best_player', env.state_size, env.action_size, config.MCTS_SIMS, config.CPUCT, best_NN)\n",
    "#user_player = User('player1', env.state_size, env.action_size)\n",
    "iteration = 0\n",
    "\n",
    "while 1:\n",
    "\n",
    "    iteration += 1\n",
    "    reload(lg)\n",
    "    reload(config)\n",
    "    \n",
    "    print('ITERATION NUMBER ' + str(iteration))\n",
    "    \n",
    "    lg.logger_main.info('BEST PLAYER VERSION: %d', best_player_version)\n",
    "    print('BEST PLAYER VERSION ' + str(best_player_version))\n",
    "\n",
    "    ######## SELF PLAY ########\n",
    "    print('SELF PLAYING ' + str(config.EPISODES) + ' EPISODES...')\n",
    "    _, memory, _, _ = playMatches(best_player, best_player,config.EPISODES , lg.logger_main, turns_until_tau0 = config.TURNS_UNTIL_TAU0, memory = memory)  #######config.EPISODES\n",
    "    print('\\n')\n",
    "    \n",
    "    memory.clear_stmemory()\n",
    "    \n",
    "    if len(memory.ltmemory) >= config.MEMORY_SIZE:          ###########config.MEMORY_SIZE\n",
    "\n",
    "        ######## RETRAINING ########\n",
    "        print('RETRAINING...')\n",
    "        current_player.replay(memory.ltmemory)\n",
    "        print('')\n",
    "\n",
    "        if iteration % 5 == 0:\n",
    "            pickle.dump( memory, open( run_folder + \"memory/memory\" + str(iteration).zfill(4) + \".p\", \"wb\" ) )\n",
    "\n",
    "        lg.logger_memory.info('====================')\n",
    "        lg.logger_memory.info('NEW MEMORIES')\n",
    "        lg.logger_memory.info('====================')\n",
    "        \n",
    "        memory_samp = random.sample(memory.ltmemory, min(1000, len(memory.ltmemory)))\n",
    "        \n",
    "        for s in memory_samp:\n",
    "            current_value, current_probs, _ = current_player.get_preds(s['state'])\n",
    "            best_value, best_probs, _ = best_player.get_preds(s['state'])\n",
    "\n",
    "            lg.logger_memory.info('MCTS VALUE FOR %s: %f', s['playerTurn'], s['value'])\n",
    "            lg.logger_memory.info('CUR PRED VALUE FOR %s: %f', s['playerTurn'], current_value)\n",
    "            lg.logger_memory.info('BES PRED VALUE FOR %s: %f', s['playerTurn'], best_value)\n",
    "            lg.logger_memory.info('THE MCTS ACTION VALUES: %s', ['%.2f' % elem for elem in s['AV']]  )\n",
    "            lg.logger_memory.info('CUR PRED ACTION VALUES: %s', ['%.2f' % elem for elem in  current_probs])\n",
    "            lg.logger_memory.info('BES PRED ACTION VALUES: %s', ['%.2f' % elem for elem in  best_probs])\n",
    "            lg.logger_memory.info('ID: %s', s['state'].id)\n",
    "            lg.logger_memory.info('INPUT TO MODEL: %s', current_player.model.convertToModelInput(s['state']))\n",
    "\n",
    "            s['state'].render(lg.logger_memory)\n",
    "            \n",
    "        ######## TOURNAMENT ########\n",
    "        print('TOURNAMENT...')\n",
    "\n",
    "\n",
    "        \n",
    "        \n",
    "        scores, _, points, sp_scores = playMatches(best_player, current_player, config.EVAL_EPISODES, lg.logger_tourney, turns_until_tau0 = 0, memory = None)######config.EVAL_EPISODES\n",
    "        print('\\nSCORES')\n",
    "        print(scores)\n",
    "        print('\\nSTARTING PLAYER / NON-STARTING PLAYER SCORES')\n",
    "        print(sp_scores)\n",
    "        #print(points)\n",
    "\n",
    "        print('\\n\\n')\n",
    "\n",
    "        if scores['current_player'] > scores['best_player'] * config.SCORING_THRESHOLD:\n",
    "            best_player_version = best_player_version + 1\n",
    "            best_NN.model.set_weights(current_NN.model.get_weights())\n",
    "            best_NN.write(env.name, best_player_version)\n",
    "\n",
    "    else:\n",
    "        print('MEMORY SIZE: ' + str(len(memory.ltmemory)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The following panels are not involved in the learning process\n",
    "\n",
    "### Play matches between versions (use -1 for human player)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from game import Game\n",
    "from funcs import playMatchesBetweenVersions\n",
    "import loggers as lg\n",
    "\n",
    "env = Game()\n",
    "playMatchesBetweenVersions(env, 1, 1, 1, 10, lg.logger_tourney, 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pass a particular game state through the neural network (setup below for Connect4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gs = GameState(np.array([\n",
    "    0,0,0,0,0,0,0,\n",
    "    0,0,0,0,0,0,0,\n",
    "    0,0,0,0,0,0,0,\n",
    "    0,0,0,0,0,0,0,\n",
    "    0,0,0,0,0,0,0,\n",
    "    0,0,0,0,0,0,0\n",
    "]), 1)\n",
    "\n",
    "preds = current_player.get_preds(gs)\n",
    "\n",
    "print(preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### See the layers of the current neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_player.model.viewLayers()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Output a diagram of the neural network architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from keras.utils import plot_model\n",
    "# plot_model(current_NN.model, to_file=run_folder + 'models/model.png', show_shapes = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "52d342018cda9ad9699a6857e281f87252facc1d54fade4ea7e5fc295102ee9f"
  },
  "kernelspec": {
   "display_name": "py3_deepreinforcement",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
